{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87d7a858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Feature Data 지정하기\n",
      "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
      "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
      "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
      "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
      "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
      "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
      "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
      "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
      "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
      "\n",
      "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
      "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "2           0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
      "3           0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
      "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "...         ...        ...        ...        ...  ...        ...        ...   \n",
      "1792        0.0        0.0        0.0        1.0  ...        4.0        0.0   \n",
      "1793        1.0        0.0        0.0        0.0  ...        1.0        0.0   \n",
      "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1795        0.0        0.0        0.0        0.0  ...        2.0        0.0   \n",
      "1796        0.0        0.0        0.0        2.0  ...        8.0        0.0   \n",
      "\n",
      "      pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
      "0           0.0        0.0        6.0       13.0       10.0        0.0   \n",
      "1           0.0        0.0        0.0       11.0       16.0       10.0   \n",
      "2           0.0        0.0        0.0        3.0       11.0       16.0   \n",
      "3           0.0        0.0        7.0       13.0       13.0        9.0   \n",
      "4           0.0        0.0        0.0        2.0       16.0        4.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1792        0.0        0.0        2.0       14.0       15.0        9.0   \n",
      "1793        0.0        0.0        6.0       16.0       14.0        6.0   \n",
      "1794        0.0        0.0        2.0        9.0       13.0        6.0   \n",
      "1795        0.0        0.0        5.0       12.0       16.0       12.0   \n",
      "1796        0.0        1.0        8.0       12.0       14.0       12.0   \n",
      "\n",
      "      pixel_7_6  pixel_7_7  \n",
      "0           0.0        0.0  \n",
      "1           0.0        0.0  \n",
      "2           9.0        0.0  \n",
      "3           0.0        0.0  \n",
      "4           0.0        0.0  \n",
      "...         ...        ...  \n",
      "1792        0.0        0.0  \n",
      "1793        0.0        0.0  \n",
      "1794        0.0        0.0  \n",
      "1795        0.0        0.0  \n",
      "1796        1.0        0.0  \n",
      "\n",
      "[1797 rows x 64 columns]\n",
      "Label Data 지정하기\n",
      "0       0\n",
      "1       1\n",
      "2       2\n",
      "3       3\n",
      "4       4\n",
      "       ..\n",
      "1792    9\n",
      "1793    0\n",
      "1794    8\n",
      "1795    9\n",
      "1796    8\n",
      "Name: label, Length: 1797, dtype: int64\n",
      "Target Names 출력해 보기\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "데이터 Describe 해 보기\n",
      "       pixel_0_0    pixel_0_1    pixel_0_2    pixel_0_3    pixel_0_4  \\\n",
      "count     1797.0  1797.000000  1797.000000  1797.000000  1797.000000   \n",
      "mean         0.0     0.303840     5.204786    11.835838    11.848080   \n",
      "std          0.0     0.907192     4.754826     4.248842     4.287388   \n",
      "min          0.0     0.000000     0.000000     0.000000     0.000000   \n",
      "25%          0.0     0.000000     1.000000    10.000000    10.000000   \n",
      "50%          0.0     0.000000     4.000000    13.000000    13.000000   \n",
      "75%          0.0     0.000000     9.000000    15.000000    15.000000   \n",
      "max          0.0     8.000000    16.000000    16.000000    16.000000   \n",
      "\n",
      "         pixel_0_5    pixel_0_6    pixel_0_7    pixel_1_0    pixel_1_1  ...  \\\n",
      "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  ...   \n",
      "mean      5.781859     1.362270     0.129661     0.005565     1.993879  ...   \n",
      "std       5.666418     3.325775     1.037383     0.094222     3.196160  ...   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "50%       4.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "75%      11.000000     0.000000     0.000000     0.000000     3.000000  ...   \n",
      "max      16.000000    16.000000    15.000000     2.000000    16.000000  ...   \n",
      "\n",
      "         pixel_6_6    pixel_6_7    pixel_7_0    pixel_7_1    pixel_7_2  \\\n",
      "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000   \n",
      "mean      3.725097     0.206455     0.000556     0.279354     5.557596   \n",
      "std       4.919406     0.984401     0.023590     0.934302     5.103019   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
      "50%       1.000000     0.000000     0.000000     0.000000     4.000000   \n",
      "75%       7.000000     0.000000     0.000000     0.000000    10.000000   \n",
      "max      16.000000    13.000000     1.000000     9.000000    16.000000   \n",
      "\n",
      "         pixel_7_3    pixel_7_4    pixel_7_5    pixel_7_6    pixel_7_7  \n",
      "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  \n",
      "mean     12.089037    11.809126     6.764051     2.067891     0.364496  \n",
      "std       4.374694     4.933947     5.900623     4.090548     1.860122  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%      11.000000    10.000000     0.000000     0.000000     0.000000  \n",
      "50%      13.000000    14.000000     6.000000     0.000000     0.000000  \n",
      "75%      16.000000    16.000000    12.000000     2.000000     0.000000  \n",
      "max      16.000000    16.000000    16.000000    16.000000    16.000000  \n",
      "\n",
      "[8 rows x 64 columns]\n",
      "decision_tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        31\n",
      "           1       0.84      0.82      0.83        38\n",
      "           2       0.73      0.87      0.80        38\n",
      "           3       0.71      0.74      0.73        27\n",
      "           4       0.94      0.80      0.87        41\n",
      "           5       0.87      0.94      0.90        35\n",
      "           6       0.87      0.89      0.88        38\n",
      "           7       0.91      0.94      0.93        34\n",
      "           8       0.79      0.77      0.78        35\n",
      "           9       0.80      0.77      0.79        43\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.85      0.85      0.84       360\n",
      "weighted avg       0.85      0.84      0.85       360\n",
      "\n",
      "random_forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        31\n",
      "           1       0.97      0.97      0.97        38\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       0.96      0.96      0.96        27\n",
      "           4       0.95      0.98      0.96        41\n",
      "           5       0.97      1.00      0.99        35\n",
      "           6       1.00      0.97      0.99        38\n",
      "           7       0.97      1.00      0.99        34\n",
      "           8       0.97      0.94      0.96        35\n",
      "           9       0.98      0.98      0.98        43\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.98      0.97      0.97       360\n",
      "\n",
      "svm_model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        31\n",
      "           1       0.95      1.00      0.97        38\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       0.96      0.96      0.96        27\n",
      "           4       0.98      0.98      0.98        41\n",
      "           5       1.00      1.00      1.00        35\n",
      "           6       1.00      1.00      1.00        38\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.97      0.94      0.96        35\n",
      "           9       0.98      0.98      0.98        43\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "sgd_model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        31\n",
      "           1       0.92      0.89      0.91        38\n",
      "           2       1.00      0.95      0.97        38\n",
      "           3       0.93      0.96      0.95        27\n",
      "           4       1.00      0.98      0.99        41\n",
      "           5       0.97      1.00      0.99        35\n",
      "           6       1.00      0.97      0.99        38\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.79      0.94      0.86        35\n",
      "           9       1.00      0.91      0.95        43\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n",
      "logistic_model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        31\n",
      "           1       0.95      0.97      0.96        38\n",
      "           2       1.00      0.97      0.99        38\n",
      "           3       0.96      0.93      0.94        27\n",
      "           4       0.93      1.00      0.96        41\n",
      "           5       0.94      0.97      0.96        35\n",
      "           6       1.00      0.97      0.99        38\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.94      0.94      0.94        35\n",
      "           9       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "Decision Tree 정확도: 0.84\n",
      "Random Forest 정확도: 0.97\n",
      "SVM 정확도: 0.98\n",
      "SGDClassifier 정확도: 0.96\n",
      "Logistic Regression 정확도: 0.97\n"
     ]
    }
   ],
   "source": [
    "#project 1\n",
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)\n",
    "\n",
    "#(1) 필요한 모듈 import하기\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#(2) 데이터 준비\n",
    "digits = load_digits()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#(3) 데이터 이해하기\n",
    "feature_data = pd.DataFrame(digits.data, columns=digits.feature_names)\n",
    "print(f'Feature Data 지정하기\\n{feature_data}')\n",
    "label_data = pd.Series(digits.target, name='label')\n",
    "print(f'Label Data 지정하기\\n{label_data}')\n",
    "target_names = digits.target_names\n",
    "print(f'Target Names 출력해 보기\\n{target_names}')\n",
    "data_description = feature_data.describe()\n",
    "print(f'데이터 Describe 해 보기\\n{data_description}')\n",
    "\n",
    "#(4) train, test 데이터 분리\n",
    "X = digits.data\n",
    "y = digits.target \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=15)\n",
    "\n",
    "#(5) 다양한 모델로 학습시켜보기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=15)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "print(f'decision_tree')\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=15)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "print(f'random_forest')\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC(random_state=15)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(f'svm_model')\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier(random_state=15)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd_model.predict(X_test)\n",
    "print(f'sgd_model')\n",
    "print(classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter=10000, random_state=15)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_lr = logistic_model.predict(X_test)\n",
    "print(f'logistic_model')\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "#모델 정확도 평가\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree 정확도: {accuracy:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest 정확도: {accuracy:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM 정확도: {accuracy:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_sgd)\n",
    "print(f\"SGDClassifier 정확도: {accuracy:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression 정확도: {accuracy:.2f}\")\n",
    "\n",
    "#가장 적합한 모델은 SVM이다. 다중 클래스 분류 문제이므로 F1-Score지표를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6ccff8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Data 지정하기\n",
      "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "..       ...         ...   ...                ...        ...            ...   \n",
      "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
      "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
      "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
      "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
      "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
      "\n",
      "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0          3.06                  0.28             2.29             5.64  1.04   \n",
      "1          2.76                  0.26             1.28             4.38  1.05   \n",
      "2          3.24                  0.30             2.81             5.68  1.03   \n",
      "3          3.49                  0.24             2.18             7.80  0.86   \n",
      "4          2.69                  0.39             1.82             4.32  1.04   \n",
      "..          ...                   ...              ...              ...   ...   \n",
      "173        0.61                  0.52             1.06             7.70  0.64   \n",
      "174        0.75                  0.43             1.41             7.30  0.70   \n",
      "175        0.69                  0.43             1.35            10.20  0.59   \n",
      "176        0.68                  0.53             1.46             9.30  0.60   \n",
      "177        0.76                  0.56             1.35             9.20  0.61   \n",
      "\n",
      "     od280/od315_of_diluted_wines  proline  \n",
      "0                            3.92   1065.0  \n",
      "1                            3.40   1050.0  \n",
      "2                            3.17   1185.0  \n",
      "3                            3.45   1480.0  \n",
      "4                            2.93    735.0  \n",
      "..                            ...      ...  \n",
      "173                          1.74    740.0  \n",
      "174                          1.56    750.0  \n",
      "175                          1.56    835.0  \n",
      "176                          1.62    840.0  \n",
      "177                          1.60    560.0  \n",
      "\n",
      "[178 rows x 13 columns]\n",
      "Label Data 지정하기\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "173    2\n",
      "174    2\n",
      "175    2\n",
      "176    2\n",
      "177    2\n",
      "Name: label, Length: 178, dtype: int64\n",
      "Target Names 출력해 보기\n",
      "['class_0' 'class_1' 'class_2']\n",
      "데이터 Describe 해 보기\n",
      "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
      "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
      "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
      "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
      "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
      "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
      "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
      "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
      "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
      "\n",
      "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
      "count     178.000000  178.000000            178.000000       178.000000   \n",
      "mean        2.295112    2.029270              0.361854         1.590899   \n",
      "std         0.625851    0.998859              0.124453         0.572359   \n",
      "min         0.980000    0.340000              0.130000         0.410000   \n",
      "25%         1.742500    1.205000              0.270000         1.250000   \n",
      "50%         2.355000    2.135000              0.340000         1.555000   \n",
      "75%         2.800000    2.875000              0.437500         1.950000   \n",
      "max         3.880000    5.080000              0.660000         3.580000   \n",
      "\n",
      "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
      "count       178.000000  178.000000                    178.000000   178.000000  \n",
      "mean          5.058090    0.957449                      2.611685   746.893258  \n",
      "std           2.318286    0.228572                      0.709990   314.907474  \n",
      "min           1.280000    0.480000                      1.270000   278.000000  \n",
      "25%           3.220000    0.782500                      1.937500   500.500000  \n",
      "50%           4.690000    0.965000                      2.780000   673.500000  \n",
      "75%           6.200000    1.120000                      3.170000   985.000000  \n",
      "max          13.000000    1.710000                      4.000000  1680.000000  \n",
      "decision_tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        12\n",
      "           1       0.91      0.83      0.87        12\n",
      "           2       0.92      0.92      0.92        12\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.92      0.92      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n",
      "random_forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "svm_model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        12\n",
      "           1       0.50      0.92      0.65        12\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.43      0.61      0.50        36\n",
      "weighted avg       0.43      0.61      0.50        36\n",
      "\n",
      "sgd_model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        12\n",
      "           1       1.00      0.50      0.67        12\n",
      "           2       0.67      1.00      0.80        12\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.83      0.78      0.77        36\n",
      "weighted avg       0.83      0.78      0.77        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.86      1.00      0.92        12\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.95        36\n",
      "\n",
      "Decision Tree 정확도: 0.92\n",
      "Random Forest 정확도: 1.00\n",
      "SVM 정확도: 0.61\n",
      "SGDClassifier 정확도: 0.78\n",
      "Logistic Regression 정확도: 0.94\n"
     ]
    }
   ],
   "source": [
    "#project2\n",
    "#(1) 필요한 모듈 import하기\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#(2) 데이터 준비\n",
    "wine = load_wine()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#(3) 데이터 이해하기\n",
    "feature_data = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "print(f'Feature Data 지정하기\\n{feature_data}')\n",
    "label_data = pd.Series(wine.target, name='label')\n",
    "print(f'Label Data 지정하기\\n{label_data}')\n",
    "target_names = wine.target_names\n",
    "print(f'Target Names 출력해 보기\\n{target_names}')\n",
    "data_description = feature_data.describe()\n",
    "print(f'데이터 Describe 해 보기\\n{data_description}')\n",
    "\n",
    "#(4) train, test 데이터 분리\n",
    "X = wine.data\n",
    "y = wine.target \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=15)\n",
    "\n",
    "#(5) 다양한 모델로 학습시켜보기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=15)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "print(f'decision_tree')\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=15)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "print(f'random_forest')\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC(random_state=15)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(f'svm_model')\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier(random_state=15)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd_model.predict(X_test)\n",
    "print(f'sgd_model')\n",
    "print(classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter=10000, random_state=15)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_lr = logistic_model.predict(X_test)\n",
    "print(f'logistic_model')\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "#모델 정확도 평가\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree 정확도: {accuracy:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest 정확도: {accuracy:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM 정확도: {accuracy:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_sgd)\n",
    "print(f\"SGDClassifier 정확도: {accuracy:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression 정확도: {accuracy:.2f}\")\n",
    "\n",
    "#가장 적합한 모델은 Random Forest이다. 정확도가 100%센트였다. 다중 클래스 분류 문제이므로 F1-Score지표를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940aabbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Data 지정하기\n",
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
      "0                   0.07871  ...        25.380          17.33   \n",
      "1                   0.05667  ...        24.990          23.41   \n",
      "2                   0.05999  ...        23.570          25.53   \n",
      "3                   0.09744  ...        14.910          26.50   \n",
      "4                   0.05883  ...        22.540          16.67   \n",
      "..                      ...  ...           ...            ...   \n",
      "564                 0.05623  ...        25.450          26.40   \n",
      "565                 0.05533  ...        23.690          38.25   \n",
      "566                 0.05648  ...        18.980          34.12   \n",
      "567                 0.07016  ...        25.740          39.42   \n",
      "568                 0.05884  ...         9.456          30.37   \n",
      "\n",
      "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
      "0             184.60      2019.0           0.16220            0.66560   \n",
      "1             158.80      1956.0           0.12380            0.18660   \n",
      "2             152.50      1709.0           0.14440            0.42450   \n",
      "3              98.87       567.7           0.20980            0.86630   \n",
      "4             152.20      1575.0           0.13740            0.20500   \n",
      "..               ...         ...               ...                ...   \n",
      "564           166.10      2027.0           0.14100            0.21130   \n",
      "565           155.00      1731.0           0.11660            0.19220   \n",
      "566           126.70      1124.0           0.11390            0.30940   \n",
      "567           184.60      1821.0           0.16500            0.86810   \n",
      "568            59.16       268.6           0.08996            0.06444   \n",
      "\n",
      "     worst concavity  worst concave points  worst symmetry  \\\n",
      "0             0.7119                0.2654          0.4601   \n",
      "1             0.2416                0.1860          0.2750   \n",
      "2             0.4504                0.2430          0.3613   \n",
      "3             0.6869                0.2575          0.6638   \n",
      "4             0.4000                0.1625          0.2364   \n",
      "..               ...                   ...             ...   \n",
      "564           0.4107                0.2216          0.2060   \n",
      "565           0.3215                0.1628          0.2572   \n",
      "566           0.3403                0.1418          0.2218   \n",
      "567           0.9387                0.2650          0.4087   \n",
      "568           0.0000                0.0000          0.2871   \n",
      "\n",
      "     worst fractal dimension  \n",
      "0                    0.11890  \n",
      "1                    0.08902  \n",
      "2                    0.08758  \n",
      "3                    0.17300  \n",
      "4                    0.07678  \n",
      "..                       ...  \n",
      "564                  0.07115  \n",
      "565                  0.06637  \n",
      "566                  0.07820  \n",
      "567                  0.12400  \n",
      "568                  0.07039  \n",
      "\n",
      "[569 rows x 30 columns]\n",
      "Label Data 지정하기\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "564    0\n",
      "565    0\n",
      "566    0\n",
      "567    0\n",
      "568    1\n",
      "Name: label, Length: 569, dtype: int64\n",
      "Target Names 출력해 보기\n",
      "['malignant' 'benign']\n",
      "데이터 Describe 해 보기\n",
      "       mean radius  mean texture  mean perimeter    mean area  \\\n",
      "count   569.000000    569.000000      569.000000   569.000000   \n",
      "mean     14.127292     19.289649       91.969033   654.889104   \n",
      "std       3.524049      4.301036       24.298981   351.914129   \n",
      "min       6.981000      9.710000       43.790000   143.500000   \n",
      "25%      11.700000     16.170000       75.170000   420.300000   \n",
      "50%      13.370000     18.840000       86.240000   551.100000   \n",
      "75%      15.780000     21.800000      104.100000   782.700000   \n",
      "max      28.110000     39.280000      188.500000  2501.000000   \n",
      "\n",
      "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
      "count       569.000000        569.000000      569.000000           569.000000   \n",
      "mean          0.096360          0.104341        0.088799             0.048919   \n",
      "std           0.014064          0.052813        0.079720             0.038803   \n",
      "min           0.052630          0.019380        0.000000             0.000000   \n",
      "25%           0.086370          0.064920        0.029560             0.020310   \n",
      "50%           0.095870          0.092630        0.061540             0.033500   \n",
      "75%           0.105300          0.130400        0.130700             0.074000   \n",
      "max           0.163400          0.345400        0.426800             0.201200   \n",
      "\n",
      "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
      "count     569.000000              569.000000  ...    569.000000   \n",
      "mean        0.181162                0.062798  ...     16.269190   \n",
      "std         0.027414                0.007060  ...      4.833242   \n",
      "min         0.106000                0.049960  ...      7.930000   \n",
      "25%         0.161900                0.057700  ...     13.010000   \n",
      "50%         0.179200                0.061540  ...     14.970000   \n",
      "75%         0.195700                0.066120  ...     18.790000   \n",
      "max         0.304000                0.097440  ...     36.040000   \n",
      "\n",
      "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
      "count     569.000000       569.000000   569.000000        569.000000   \n",
      "mean       25.677223       107.261213   880.583128          0.132369   \n",
      "std         6.146258        33.602542   569.356993          0.022832   \n",
      "min        12.020000        50.410000   185.200000          0.071170   \n",
      "25%        21.080000        84.110000   515.300000          0.116600   \n",
      "50%        25.410000        97.660000   686.500000          0.131300   \n",
      "75%        29.720000       125.400000  1084.000000          0.146000   \n",
      "max        49.540000       251.200000  4254.000000          0.222600   \n",
      "\n",
      "       worst compactness  worst concavity  worst concave points  \\\n",
      "count         569.000000       569.000000            569.000000   \n",
      "mean            0.254265         0.272188              0.114606   \n",
      "std             0.157336         0.208624              0.065732   \n",
      "min             0.027290         0.000000              0.000000   \n",
      "25%             0.147200         0.114500              0.064930   \n",
      "50%             0.211900         0.226700              0.099930   \n",
      "75%             0.339100         0.382900              0.161400   \n",
      "max             1.058000         1.252000              0.291000   \n",
      "\n",
      "       worst symmetry  worst fractal dimension  \n",
      "count      569.000000               569.000000  \n",
      "mean         0.290076                 0.083946  \n",
      "std          0.061867                 0.018061  \n",
      "min          0.156500                 0.055040  \n",
      "25%          0.250400                 0.071460  \n",
      "50%          0.282200                 0.080040  \n",
      "75%          0.317900                 0.092080  \n",
      "max          0.663800                 0.207500  \n",
      "\n",
      "[8 rows x 30 columns]\n",
      "decision_tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92        39\n",
      "           1       0.94      0.99      0.96        75\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "random_forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89        39\n",
      "           1       0.92      0.97      0.95        75\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "svm_model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78        39\n",
      "           1       0.85      0.97      0.91        75\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.89      0.82      0.84       114\n",
      "weighted avg       0.88      0.87      0.86       114\n",
      "\n",
      "sgd_model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79        39\n",
      "           1       0.91      0.84      0.87        75\n",
      "\n",
      "    accuracy                           0.84       114\n",
      "   macro avg       0.82      0.84      0.83       114\n",
      "weighted avg       0.85      0.84      0.84       114\n",
      "\n",
      "logistic_model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84        39\n",
      "           1       0.91      0.93      0.92        75\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.88      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "Decision Tree 정확도: 0.95\n",
      "Random Forest 정확도: 0.93\n",
      "SVM 정확도: 0.87\n",
      "SGDClassifier 정확도: 0.84\n",
      "Logistic Regression 정확도: 0.89\n"
     ]
    }
   ],
   "source": [
    "#project3\n",
    "#(1) 필요한 모듈 import하기\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#(2) 데이터 준비\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#(3) 데이터 이해하기\n",
    "feature_data = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "print(f'Feature Data 지정하기\\n{feature_data}')\n",
    "label_data = pd.Series(breast_cancer.target, name='label')\n",
    "print(f'Label Data 지정하기\\n{label_data}')\n",
    "target_names = breast_cancer.target_names\n",
    "print(f'Target Names 출력해 보기\\n{target_names}')\n",
    "data_description = feature_data.describe()\n",
    "print(f'데이터 Describe 해 보기\\n{data_description}')\n",
    "\n",
    "#(4) train, test 데이터 분리\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=15)\n",
    "\n",
    "#(5) 다양한 모델로 학습시켜보기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=15)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "print(f'decision_tree')\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=15)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "print(f'random_forest')\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC(random_state=15)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(f'svm_model')\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier(random_state=15)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd_model.predict(X_test)\n",
    "print(f'sgd_model')\n",
    "print(classification_report(y_test, y_pred_sgd))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter=10000, random_state=15)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_lr = logistic_model.predict(X_test)\n",
    "print(f'logistic_model')\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "#모델 정확도 평가\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree 정확도: {accuracy:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest 정확도: {accuracy:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM 정확도: {accuracy:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_sgd)\n",
    "print(f\"SGDClassifier 정확도: {accuracy:.2f}\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression 정확도: {accuracy:.2f}\")\n",
    "\n",
    "#유방암 진단 문제에서는 Recall [1] 이 암 양성이기 때문에 가장 중요한 지표이다. 따라서 Recall 값이 가장 높은 Decision Tree 모델이 가장 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3493ecee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
